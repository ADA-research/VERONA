{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d01b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ada_verona import (\n",
    "    AttackEstimationModule,\n",
    "    AutoAttackWrapper,\n",
    "    BinarySearchEpsilonValueEstimator,\n",
    "    ExperimentRepository,\n",
    "    ImageFileDataset,\n",
    "    Network,\n",
    "    One2AnyPropertyGenerator,\n",
    "    PGDAttack,\n",
    "    PredictionsBasedSampler,\n",
    "    PytorchExperimentDataset,\n",
    "    VerificationContext,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed9ed1",
   "metadata": {},
   "source": [
    "## Guide on how to compute upper bounds to Robustness Distributions using adversarial attacks with ada-verona. \n",
    "\n",
    "The notebook shows how to use the different components of the standalone [ada-verona](https://github.com/henba1/ada-verona) package for computing robustness distributions of neural networks [1,2]. \n",
    "If these experiments are executed in a non-notebook context, one can make use of the `ExperimentRepostory` class to create and organise experiments in a structured manner.\n",
    "To see examples on how to use the `ExperimentRepostory` class, take a look at the example scripts in the `scripts/` folder.\n",
    "\n",
    "\n",
    "\n",
    "**Note:**  \n",
    "This package does _not_ include [auto-verify](https://github.com/ADA-research/auto-verify) by default. However, you can easily integrate your own verifiers using the interface in `verification_runner.py`.\n",
    "\n",
    "We'll cover:\n",
    "- Loading Models and Datasets with ada-verona\n",
    "- Running PGD and AutoAttack experiments\n",
    "- Integrating your own verifier\n",
    "\n",
    "---\n",
    "## 0. Setup\n",
    "\n",
    "Make sure you have installed the ada-verona package from PyPI. **#TODO** highlight how to install ada-verona and the prerequisites\n",
    "\n",
    "You need a trained model and a dataset (e.g., MNIST).\n",
    "\n",
    "## 1. Loading Models and Datasets with VERONA\n",
    "\n",
    "The VERONA package is designed to make it easy for researchers to load models and datasets for robustness experiments.\n",
    "\n",
    "## Supported Model Format\n",
    "- **ONNX**: VERONA expects neural network models in the ONNX format (`.onnx` files).\n",
    "- You can convert PyTorch or TensorFlow models to ONNX using their respective export utilities. \n",
    "- Note: We plan to add direct support for torch models soon (3. Quarter of 2025).\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a93240e",
   "metadata": {},
   "source": [
    "### Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your ONNX model\n",
    "model_path = Path(\"data/MNIST/raw/models/mnist-net_256x2.onnx\")\n",
    "network = Network(model_path)\n",
    "\n",
    "# To load as a PyTorch model (for attacks, etc.)\n",
    "torch_model = network.load_pytorch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954ceb7",
   "metadata": {},
   "source": [
    "### Loading a Dataset\n",
    "- For standard datasets (like MNIST), use the provided wrappers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eacb09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f98b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pytorch dataset. Preprocessing can be defined in the transform parameter\n",
    "torch_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "# wrap pytorch dataset into experiment dataset to keep track of image id\n",
    "experiment_dataset = PytorchExperimentDataset(dataset=torch_dataset)\n",
    "\n",
    "# work on subset of the dataset to keep experiment small\n",
    "experiment_dataset = experiment_dataset.get_subset([x for x in range(0, 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9db08",
   "metadata": {},
   "source": [
    "- For custom datasets (e.g., images on disk):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2788eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = Path(\"path/to/images\")\n",
    "label_file = Path(\"path/to/labels.csv\")\n",
    "custom_dataset = ImageFileDataset(image_folder=image_folder, label_file=label_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78982b5",
   "metadata": {},
   "source": [
    "### Sampling and Experiment Context\n",
    "- Use the `ExperimentRepository` to manage experiments and create verification contexts. In this example, a one to any property generator is used that creates vnnlib files for one to any robustness queries. A one to one property generator is also already implemented in the package and could be used here as well. For the property generator, we have to define the number of classes, the lower bound of the data and the upper bound of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ef980",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_repository = ExperimentRepository(base_path=Path(\"experiments/\"), network_folder=Path(\"models/\"))\n",
    "network = experiment_repository.get_network_list()[0]\n",
    "data_point = experiment_dataset[0]\n",
    "property_generator = One2AnyPropertyGenerator()\n",
    "verification_context = experiment_repository.create_verification_context(network, data_point, property_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ead885",
   "metadata": {},
   "source": [
    "**For more details, see the [VERONA wiki](https://deepwiki.com/ADA-research/VERONA).** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265e62d",
   "metadata": {},
   "source": [
    "## 2. Run PGD and AutoAttack Experiments \n",
    "\n",
    "Below is a minimal example for running PGD [3] and AutoAttack-based [4,5] robustness estimation.\n",
    "\n",
    "- **Tip:** For more examples see the scripts in the `scripts/` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd943923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataset and experiment repository\n",
    "torch.manual_seed(0)\n",
    "epsilon_list = [0.001, 0.005, 0.05, 0.08]\n",
    "experiment_repository_path = Path(\"../tests/test_experiment\")\n",
    "network_folder = Path(\"data/MNIST/raw/models\")\n",
    "\n",
    "torch_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "dataset = PytorchExperimentDataset(dataset=torch_dataset)\n",
    "experiment_repository = ExperimentRepository(base_path=experiment_repository_path, network_folder=network_folder)\n",
    "property_generator = One2AnyPropertyGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac23c9",
   "metadata": {},
   "source": [
    "To compute the robustness of a network, one first has to check which data points are classified correctly. For that the PredictionsBasedSampler class is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e110a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sampler = PredictionsBasedSampler(sample_correct_predictions=True)\n",
    "\n",
    "# Here all the data points that are correctly predicted by the network are sampled\n",
    "sampled_data = dataset_sampler.sample(network, experiment_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf56b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD Attack\n",
    "verifier_pgd = AttackEstimationModule(attack=PGDAttack(number_iterations=10, step_size=0.01))\n",
    "epsilon_value_estimator_pgd = BinarySearchEpsilonValueEstimator(\n",
    "    epsilon_value_list=epsilon_list.copy(), verifier=verifier_pgd\n",
    ")\n",
    "\n",
    "# AutoAttack\n",
    "verifier_autoattack = AttackEstimationModule(attack=AutoAttackWrapper())\n",
    "epsilon_value_estimator_auto = BinarySearchEpsilonValueEstimator(\n",
    "    epsilon_value_list=epsilon_list.copy(), verifier=verifier_autoattack\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d2a6d",
   "metadata": {},
   "source": [
    "We use the pgd \"verifier\" `verifier_pgd ` from here on as an example for the next cells for illustrative purposes. Note that the verifier is used as a parameter to the Epsilon Estimator`epsilon_value_estimator_pgd`. The epsilon value estimator determines which search strategy is used to find adversarial examples (or, more precisely, estimate the interval of perturbation magnitude where the classification outcome changes). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91273abd",
   "metadata": {},
   "source": [
    "### Run the experiment (example for PGD)\n",
    "\n",
    "Here is a minimal example for one network and one data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = experiment_repository.get_network_list()[0]\n",
    "data_point = dataset[0]\n",
    "verification_context = experiment_repository.create_verification_context(network, data_point, property_generator)\n",
    "result = epsilon_value_estimator_pgd.compute_epsilon_value(verification_context)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c1735",
   "metadata": {},
   "source": [
    "The slightly more elaborate example below computes critical epsilon values for a given network and datapoint and again defines a verification context. The folder for intermediate results needs to be provided to the VerificationContext, so the vnnlib files can be stored there. In addition, the results of the epsilon values queries can also be stored there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c85694",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "now = datetime.now()\n",
    "now_string = now.strftime(\"%d-%m-%Y+%H_%M\")\n",
    "\n",
    "# Here the intermediate results (the per epsilon queries )\n",
    "intermediate_result_base_path = Path(f\"intermediate_results/{now_string}\")\n",
    "\n",
    "for data_point in sampled_data:\n",
    "    network_name = network.path.name.split(\".\")[0]\n",
    "    intermediate_result_path = Path(intermediate_result_base_path / f\"{network_name}/image_{data_point.id}\")\n",
    "\n",
    "    verification_context = VerificationContext(\n",
    "        network,\n",
    "        data_point,\n",
    "        intermediate_result_path,\n",
    "        property_generator=property_generator,\n",
    "    )\n",
    "    epsilon_value_result = epsilon_value_estimator_pgd.compute_epsilon_value(verification_context)\n",
    "\n",
    "    print(f\"result: {epsilon_value_result}\")\n",
    "    results.append(epsilon_value_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5ac057",
   "metadata": {},
   "source": [
    "### If you have questions or want to contribute, open an issue or pull request on our central [VERONA GitHub](https://github.com/ADA-research/VERONA/issues)! Please also refer to our [VERONA wiki](https://deepwiki.com/ADA-research/VERONA) and  the more detailed examples in the `scripts/` folder. \n",
    "\n",
    "Disclaimer: The [VERONA wiki](https://deepwiki.com/ADA-research/VERONA) entails the [auto-verify](https://github.com/ADA-research/auto-verify) integration which the ada-verona package foregoes in favor of a leaner package composition. If you want to use the verifiers supported by [auto-verify](https://github.com/ADA-research/auto-verify) and do not wish to tinker with integrating your own verifiers, then we can refer to our ada-auto-verona package.\n",
    "\n",
    "**#TODO**: once package is up, add the link here. Prob. needs a catchier name also. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc8438",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "[1] A. W. Bosman, H. H. Hoos, and J. N. van Rijn, “A Preliminary Study of Critical Robustness Distributions in Neural Network Verification,” Proceedings of the 6th workshop on formal methods for ML-enabled autonomous systems, 2023. Available: https://ada.liacs.leidenuniv.nl/papers/BosEtAl23.pdf\n",
    "\n",
    "\n",
    "[2] A. Berger, N. Eberhardt, A. W. Bosman, H. Duwe, J. N. van Rijn, and H. Hoos, “Empirical Analysis of Upper Bounds of Robustness Distributions using Adversarial Attacks,” in THE 19TH LEARNING AND IN℡LIGENT OPTIMIZATION CONFERENCE, Accessed: Jul. 15, 2025. [Online]. Available: https://openreview.net/forum?id=jsfqoRrsjy\n",
    "\n",
    "[3] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards Deep Learning Models Resistant to Adversarial Attacks,” presented at the International Conference on Learning Representations, Feb. 2018. Accessed: Dec. 20, 2024. [Online]. Available: https://openreview.net/forum?id=rJzIBfZAb\n",
    "\n",
    "\n",
    "[4] F. Croce and M. Hein, “Mind the box: l_1 -APGD for sparse adversarial attacks on image classifiers,” in International Conference on Machine Learning, PMLR, 2021, pp. 2201–2211. Accessed: Jul. 16, 2025. [Online]. Available: http://proceedings.mlr.press/v139/croce21a.html\n",
    "[5] F. Croce and M. Hein, “Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks,” in International conference on machine learning, PMLR, 2020, pp. 2206–2216. Accessed: May 03, 2025. [Online]. Available: https://proceedings.mlr.press/v119/croce20b.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verona",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
