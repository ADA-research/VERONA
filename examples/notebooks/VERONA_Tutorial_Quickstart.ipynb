{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart VERONA tutorial\n",
    "\n",
    "In this section, we describe the main components of the VERONA API required to perform full-set robustness evaluation experiments.  \n",
    "We illustrate these components by providing examples of concrete classes we readily provide in VERONA.\n",
    "\n",
    "\n",
    "## Datasets\n",
    "The first step is to import a dataset. VERONA supports two main options:  \n",
    "(i) loading a custom dataset (see the README for details on the required file structure), or  \n",
    "(ii) reusing existing datasets available through torchvision.  \n",
    "We illustrate the first with the MNIST dataset examples available in examples/example_experiment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ada_verona.database.experiment_dataset import ExperimentDataset\n",
    "from ada_verona.database.image_file_dataset import ImageFileDataset\n",
    "from ada_verona.database.pytorch_experiment_dataset import PytorchExperimentDataset\n",
    "\n",
    "# Import a custom dataset\n",
    "# The required file structure is described in the README\n",
    "dataset = ImageFileDataset(\n",
    "    image_folder= Path(\"../example_experiment/data/images\"), \n",
    "    label_file=Path(\"../example_experiment/data/image_labels.csv\"), \n",
    "    preprocessing=None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERONA also includes dataset samplers.  \n",
    "These allow you to restrict verification to specific subsets of data, for example, only verifying correctly classified instances or several samples from each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ada_verona.dataset_sampler.dataset_sampler import DatasetSampler\n",
    "from ada_verona.dataset_sampler.predictions_based_sampler import PredictionsBasedSampler\n",
    "\n",
    "# A sampler based on model predictions  \n",
    "# sample_correct_predictions = True: only include correctly classified instances  \n",
    "# sample_correct_predictions = False : only include misclassified instances  \n",
    "sampler = PredictionsBasedSampler(\n",
    "    sample_correct_predictions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness Evaluation Algorithms\n",
    "The next step is to determine which algorithm will be used to evaluate robustness.  \n",
    "VERONA supports complete verifiers as well as commonly used adversarial attacks.  \n",
    "We illustrate the use of a readily available attack, called PGD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from ada_verona.verification_module.attacks.pgd_attack import PGDAttack\n",
    "from ada_verona.verification_module.attack_estimation_module import AttackEstimationModule\n",
    "\n",
    "# Define a PGD attack instance\n",
    "attack = PGDAttack(\n",
    "    number_iterations=100,\n",
    "    stepsize=0.2,\n",
    "    randomise=True\n",
    ")\n",
    "\n",
    "verifier = AttackEstimationModule(attack=attack)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators \n",
    "\n",
    "The $\\varepsilon$ values at which robustness is evaluated can be chosen in different ways.  \n",
    "Currently, two estimators are supported:  \n",
    "(i) an iterative search, which evaluates all user-specified $\\varepsilon$ values, and  \n",
    "(ii) a binary search, which efficiently identifies adjacent unsat and sat values to approximate $\\tilde{\\varepsilon}^*$.  \n",
    "\n",
    "We illustrate the binary search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ada_verona.epsilon_value_estimator.epsilon_value_estimator import EpsilonValueEstimator\n",
    "from ada_verona.epsilon_value_estimator.iterative_value_estimator import IterativeValueEstimator\n",
    "from ada_verona.epsilon_value_estimator.binary_search_epsilon_value_estimator import BinarySearchEpsilonValueEstimator\n",
    "\n",
    "# Select the epsilon estimator\n",
    "epsilons = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "\n",
    "# Binary search\n",
    "# Finds adjacent unsat and sat values in epsilons\n",
    "estimator = BinarySearchEpsilonValueEstimator(\n",
    "    epsilon_value_list=epsilons,\n",
    "    verifier=verifier\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property generators\n",
    "\n",
    "A property generator specifies the property to be verified.  \n",
    "VERONA currently provides support for both targeted robustness (One2One) and untargeted local robustness (One2Any), expressed as vnnlib properties.  \n",
    "Adding propertygenerator is possible, but the verifier needs to be able to read and handle the property.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from ada_verona.verification_module.property_generator.one2any_property_generator import One2AnyPropertyGenerator\n",
    "\n",
    "# Select the property type\n",
    "# VERONA currently provides two common property generators (compatible with most verifiers)\n",
    "\n",
    "# Untargeted local robustness (most common)\n",
    "# Creates vnnlib properties for verifying robustness against any class\n",
    "property = One2AnyPropertyGenerator(\n",
    "    number_classes=10,\n",
    "    data_lb=0,\n",
    "    data_ub=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, an experiment can be created, configured, and executed using the experiment repository.  \n",
    "This repository manages experiment metadata, sampled data points, verification contexts, and results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ada_verona.database.experiment_repository import ExperimentRepository\n",
    "\n",
    "experiment_name = \"test_experiments\"\n",
    "experiment_repository_path=Path(\"../example_experiment\")\n",
    "network_folder=Path(\"../example_experiment/data/networks\")\n",
    "\n",
    "\n",
    "# The network folder should be a directory containing networks.\n",
    "experiment_repository = ExperimentRepository(\n",
    "    base_path= experiment_repository_path,\n",
    "    network_folder=network_folder\n",
    ")\n",
    "\n",
    "# Initialise a new experiment\n",
    "experiment_repository.initialize_new_experiment(experiment_name)\n",
    "\n",
    "# Save the experiment configuration\n",
    "experiment_repository.save_configuration(\n",
    "    dict(\n",
    "        experiment_name=experiment_name,\n",
    "        experiment_repository_path=experiment_repository_path,\n",
    "        network_folder=str(network_folder),\n",
    "        dataset=str(dataset),\n",
    "        timeout=360,\n",
    "        epsilon_list=[str(x) for x in epsilons],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run verification for each network\n",
    "for network in network_list:\n",
    "    sampled_data = dataset_sampler.sample(network, dataset)\n",
    "    for data_point in sampled_data:\n",
    "        verification_context = experiment_repository.create_verification_context(\n",
    "            network,\n",
    "            data_point,\n",
    "            property_generator\n",
    "        )\n",
    "    \n",
    "        # At this point you can either:\n",
    "        # 1. Save the VerificationContext to execute later on (e.g., via SLURM), or\n",
    "        # 2. Directly execute, as illustrated here:\n",
    "        epsilon_value_result = epsilon_value_estimator.compute_epsilon_value(\n",
    "            verification_context\n",
    "        )\n",
    "    \n",
    "        experiment_repository.save_result(epsilon_value_result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
